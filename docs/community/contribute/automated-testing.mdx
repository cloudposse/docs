---
title: Terraform Automated Testing
sidebar_label: Automated Testing
description: 'Our automated testing strategy and resources'
tags:
  - community
  - contribute
  - developer
---
import Intro from '@site/src/components/Intro';
import Steps from '@site/src/components/Steps';

All of our Terraform modules have automated tests. We have two sets of checks:

- The first set of checks is executed through the feature-branch workflow, which can be found [here](https://github.com/cloudposse/github-actions-workflows-terraform-module/blob/main/.github/workflows/feature-branch.yml)
This workflow generates some documentation and performs basic sanity checks, including linting and formatting. These checks are lightweight and can be executed without requiring any special permissions. Consequently, they *are automatically run* on every commit.
Before committing and pushing your changes, you can and should run this set of checks locally by executing the following command on your host
```
make precommit/terraform
```
Running these checks locally incorporates all the required changes that otherwise would block your PR.

- The second set of checks consists of Terraform integration tests that validate the functionality and integration of the module. These tests are performed using the [`terratest`](https://github.com/gruntwork-io/terratest) library, specifically designed for infrastructure testing, and do more in-depth integration tests of module functionality.
Unlike the first set of checks, these integration tests are *executed only on request*, and only by authorized contributors. We use ChatOps to trigger this workflow.


## Philosophy of Terraform Integration Testing

At a minimum, we ensure that all of our modules cleanly `plan`, `apply` and `destroy`. This catches 80% of the problems with only 20% of the effort. We also test than then the `enabled` input is set to `false`, no resources are created.

Ideally we would like to test that the resources are properly created, but often this is difficult to verify programmatically, in which case we settle for spot checking that the dynamic outputs match our expectations. At the same time, we do not want to waste effort retesting what has already been tested by HashiCorp and their providers. For example, we have our [`terraform-aws-s3-bucket`](https://github.com/cloudposse/terraform-aws-s3-bucket) module that creates an S3 bucket. We don't need to test that a bucket is created; we assume that would be caught by the upstream terraform tests. But we do want to [test that the bucket name](https://github.com/cloudposse/terraform-aws-s3-bucket/blob/master/test/src/examples_complete_test.go#L38) is what we expect it to be, since this is something under our control.

## Using ChatOps To Trigger Integration Tests

In addition to automatic triggers, tests can be run on demand via "ChatOps". (You will need to have at least `triage` level of access to a repo to use ChatOps commands.) Typically, tests are run by a CloudPosse contributor or team member as part of a PR review.

Tests are initiated by posting GitHub comments on the PR. Currently supported commands are the following:

| Command      | Description                                         |
| ------------ | --------------------------------------------------- |
| `/terratest` | Run the `terratest` integration tests in `test/src` |


Terraform tests run against our [testing infrastructure](https://github.com/cloudposse/testing.cloudposse.co) that we host in an isolated account on AWS, strictly for the purposes of testing infrastructure.

ChatOps is powered by [GitHub Actions](https://github.com/features/actions) and the [slash-dispatch-command](https://github.com/peter-evans/slash-command-dispatch).

The terratest workflow is defined in the [`cloudposse/actions`](https://github.com/cloudposse/actions/blob/master/.github/workflows/terratest-command.yml) repository. The benefit with this is that we have one place to control the testing
workflow for all of our hundreds of terraform modules. The downside, however, with dispatched workflows is that the _workflows_ always run from the `main` branch.

## Manually triggering a shared workflow
Here's a list a workflows you might want to trigger manually should things go wrong on GitHub side or with our configuration.
- `feature-branch` can be triggered anytime by labeling/unlabeling PR with any label.
- `release-branch` is the same to creating a GH release manually. We have created a complimentary workflow `release-published` for this case: it will fulfill the missing parts once you create a release manually. Note that you are skipping tests before release in this case.
- `scheduled` can be triggered anytime from GitHub UI, it has a *workflow_dispatch* trigger for this purpose.

## ChatOps Configuration

If you're a contributor who wants to intialize one of our terraform modules, this is the process. Note, if a repo has already been configured for chatops, there's no need to proceed with these steps.

To initialize one of our modules with chatops, run the following commands:

<Steps>
  1. `git clone` the terraform module repository
  1. `cd $repo` to enter the repository directory
  1. `make init` to initialize the build-harness
  1. `git add *` to add the changes
  1. Add the build badge to the `README.yaml` under the `badges` section.
  1. `make readme` to rebuild the `README.md` (remember, never edit the `README.md` manually since it's generated from the `README.yaml`)
  1. Open up a Pull Request with the changes. Here is a [good example](https://github.com/cloudposse/atmos/pull/555).
  1. Request a Code Review in the [`#pr-reviews`](https://slack.cloudposse.com) Slack channel (and *big* thanks for your contribution!)
</Steps>

## FAQ

### Why do my tests fail when looking up remote state for components?

If you encounter an error like:
```
Error: Attempt to get attribute from null value
...
â”‚ module.s3_bucket.outputs is null
...
This value is null, so it does not have any attributes.
```

This typically occurs when using an older version of the remote-state module. The solution is to upgrade to version 1.8.0 or higher of the `cloudposse/stack-config/yaml//modules/remote-state` module. For example:

```hcl
module "s3_bucket" {
  source  = "cloudposse/stack-config/yaml//modules/remote-state"
  version = "1.8.0"

  component = var.destination_bucket_component_name
  context   = module.this.context
}
```

### How do I handle dependencies in my tests?

When testing components that depend on other infrastructure (like EKS clusters, VPCs, or other foundational components), you need to configure and deploy these dependencies in your test suite. This is done by adding dependencies to the stack test fixtures and deploying before running the tests. For example:

```go
func TestRunSuite(t *testing.T) {
    suite := new(ComponentSuite)
    // Add dependencies
    suite.AddDependency(t, "s3-bucket/cloudwatch", "default-test", nil)
    helper.Run(t, suite)
}
```